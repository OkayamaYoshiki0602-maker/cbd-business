#!/usr/bin/env python3
"""
ãƒã‚ºã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å°‚é–€åˆ†é‡ã§ãƒã‚ºã£ã¦ã„ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’åˆ†æã—ã¦å…±é€šç‚¹ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
"""

import os
import sys
import json
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv
from collections import Counter
import re

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from social_media.x_twitter import get_twitter_client

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


def analyze_buzz_tweets(username, days=7):
    """
    ãƒã‚ºã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’åˆ†æ
    
    Args:
        username: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåï¼ˆ@ãªã—ï¼‰
        days: åˆ†ææœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    
    Returns:
        åˆ†æçµæœ
    """
    try:
        client = get_twitter_client()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
        user = client.get_user(username=username)
        if not user.data:
            print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: @{username}")
            return None
        
        user_id = user.data.id
        follower_count = user.data.public_metrics.get('followers_count', 0) if user.data.public_metrics else 0
        
        print(f"ğŸ“Š ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æ: @{username}")
        print(f"   ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {follower_count:,}")
        
        # æœ€è¿‘ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—
        tweets = client.get_users_tweets(
            id=user_id,
            max_results=100,
            tweet_fields=['created_at', 'public_metrics', 'text']
        )
        
        if not tweets.data:
            print(f"âš ï¸ ãƒ„ã‚¤ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        # åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        analysis = {
            'username': username,
            'follower_count': follower_count,
            'total_tweets': len(tweets.data),
            'high_engagement_tweets': [],
            'patterns': {
                'common_keywords': [],
                'common_structures': [],
                'engagement_indicators': []
            }
        }
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®é«˜ã„ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ½å‡º
        for tweet in tweets.data:
            metrics = tweet.public_metrics if hasattr(tweet, 'public_metrics') else {}
            likes = metrics.get('like_count', 0)
            retweets = metrics.get('retweet_count', 0)
            replies = metrics.get('reply_count', 0)
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            engagement_rate = (likes + retweets * 2 + replies * 2) / max(follower_count, 1) * 100
            
            # é«˜ã„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ½å‡ºï¼ˆä¸Šä½20%ï¼‰
            if engagement_rate > 1.0:  # 1%ä»¥ä¸Šã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡
                analysis['high_engagement_tweets'].append({
                    'text': tweet.text,
                    'likes': likes,
                    'retweets': retweets,
                    'replies': replies,
                    'engagement_rate': engagement_rate,
                    'created_at': tweet.created_at.isoformat() if tweet.created_at else None
                })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        analyze_patterns(analysis)
        
        return analysis
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None


def analyze_patterns(analysis):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
    
    Args:
        analysis: åˆ†æçµæœãƒ‡ãƒ¼ã‚¿
    """
    high_engagement_tweets = analysis['high_engagement_tweets']
    
    if not high_engagement_tweets:
        return
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    keywords = []
    for tweet in high_engagement_tweets:
        text = tweet['text']
        
        # æ•°å­—ã‚’æŠ½å‡º
        numbers = re.findall(r'\d+[%å„„ä¸‡äººä»¶]', text)
        keywords.extend(numbers)
        
        # æ—¥ä»˜ã‚’æŠ½å‡º
        dates = re.findall(r'\d{1,2}[-/]\d{1,2}', text)
        keywords.extend(dates)
        
        # ç–‘å•ç¬¦ãƒ»æ„Ÿå˜†ç¬¦ã®ä½¿ç”¨
        if '?' in text:
            keywords.append('ç–‘å•æ–‡')
        if 'ï¼' in text or '!' in text:
            keywords.append('æ„Ÿå˜†ç¬¦')
        
        # æ”¹è¡Œã®ä½¿ç”¨
        if '\n' in text:
            keywords.append('æ”¹è¡Œã‚ã‚Š')
    
    # é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    keyword_counter = Counter(keywords)
    analysis['patterns']['common_keywords'] = keyword_counter.most_common(10)
    
    # æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    structures = []
    for tweet in high_engagement_tweets:
        text = tweet['text']
        
        # æ®µè½æ•°
        paragraphs = len([p for p in text.split('\n') if p.strip()])
        structures.append(f'{paragraphs}æ®µè½')
        
        # æ–‡å­—æ•°ç¯„å›²
        length = len(text)
        if length < 100:
            structures.append('çŸ­ã„ï¼ˆ100æ–‡å­—æœªæº€ï¼‰')
        elif length < 200:
            structures.append('ä¸­ç¨‹åº¦ï¼ˆ100-200æ–‡å­—ï¼‰')
        else:
            structures.append('é•·ã„ï¼ˆ200æ–‡å­—ä»¥ä¸Šï¼‰')
    
    structure_counter = Counter(structures)
    analysis['patterns']['common_structures'] = structure_counter.most_common(10)
    
    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™
    avg_likes = sum(t['likes'] for t in high_engagement_tweets) / len(high_engagement_tweets)
    avg_retweets = sum(t['retweets'] for t in high_engagement_tweets) / len(high_engagement_tweets)
    
    analysis['patterns']['engagement_indicators'] = {
        'average_likes': avg_likes,
        'average_retweets': avg_retweets,
        'average_engagement_rate': sum(t['engagement_rate'] for t in high_engagement_tweets) / len(high_engagement_tweets)
    }


def compare_accounts(accounts_data):
    """
    è¤‡æ•°ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æ¯”è¼ƒã—ã¦å…±é€šç‚¹ã‚’æŠ½å‡º
    
    Args:
        accounts_data: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æçµæœã®ãƒªã‚¹ãƒˆ
    
    Returns:
        å…±é€šç‚¹åˆ†æçµæœ
    """
    common_patterns = {
        'common_keywords': Counter(),
        'common_structures': Counter(),
        'avg_engagement_rate': 0,
        'recommendations': []
    }
    
    # å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é›†è¨ˆ
    for account_data in accounts_data:
        if account_data and 'patterns' in account_data:
            patterns = account_data['patterns']
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é›†è¨ˆ
            for keyword, count in patterns.get('common_keywords', []):
                common_patterns['common_keywords'][keyword] += count
            
            # æ§‹é€ ã‚’é›†è¨ˆ
            for structure, count in patterns.get('common_structures', []):
                common_patterns['common_structures'][structure] += count
    
    # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    top_keywords = common_patterns['common_keywords'].most_common(5)
    top_structures = common_patterns['common_structures'].most_common(5)
    
    recommendations = []
    
    if top_keywords:
        recommendations.append(f"é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join([k for k, _ in top_keywords])}")
    
    if top_structures:
        recommendations.append(f"æ¨å¥¨æ§‹é€ : {', '.join([s for s, _ in top_structures])}")
    
    common_patterns['recommendations'] = recommendations
    
    return common_patterns


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python buzz_analyzer.py analyze <username> [days]")
        print("  python buzz_analyzer.py compare <username1> <username2> ...")
        print("\nä¾‹:")
        print("  python buzz_analyzer.py analyze example_user 7")
        print("  python buzz_analyzer.py compare user1 user2 user3")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == 'analyze':
        if len(sys.argv) < 3:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå¿…è¦ã§ã™")
            sys.exit(1)
        
        username = sys.argv[2].replace('@', '')
        days = int(sys.argv[3]) if len(sys.argv) > 3 else 7
        
        result = analyze_buzz_tweets(username, days)
        
        if result:
            print("\nğŸ“Š åˆ†æçµæœ:")
            print("=" * 60)
            print(f"é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆ: {len(result['high_engagement_tweets'])}ä»¶")
            print(f"\né »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
            for keyword, count in result['patterns']['common_keywords'][:5]:
                print(f"  - {keyword}: {count}å›")
            print(f"\næ¨å¥¨æ§‹é€ :")
            for structure, count in result['patterns']['common_structures'][:5]:
                print(f"  - {structure}: {count}å›")
            print(f"\nå¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {result['patterns']['engagement_indicators']['average_engagement_rate']:.2f}%")
    
    elif command == 'compare':
        if len(sys.argv) < 3:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå¿…è¦ã§ã™")
            sys.exit(1)
        
        usernames = [u.replace('@', '') for u in sys.argv[2:]]
        accounts_data = []
        
        for username in usernames:
            print(f"\nğŸ“Š åˆ†æä¸­: @{username}")
            result = analyze_buzz_tweets(username)
            if result:
                accounts_data.append(result)
        
        if accounts_data:
            common_patterns = compare_accounts(accounts_data)
            
            print("\nğŸ“Š å…±é€šç‚¹åˆ†æçµæœ:")
            print("=" * 60)
            print(f"\nå…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
            for keyword, count in common_patterns['common_keywords'].most_common(10):
                print(f"  - {keyword}: {count}å›")
            print(f"\næ¨å¥¨æ§‹é€ :")
            for structure, count in common_patterns['common_structures'].most_common(10):
                print(f"  - {structure}: {count}å›")
            print(f"\næ¨å¥¨äº‹é …:")
            for rec in common_patterns['recommendations']:
                print(f"  - {rec}")
    
    else:
        print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
        sys.exit(1)


if __name__ == '__main__':
    main()
