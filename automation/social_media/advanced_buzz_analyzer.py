#!/usr/bin/env python3
"""
é«˜åº¦ãªãƒã‚ºã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ„ã‚¤ãƒ¼ãƒˆå†…å®¹ã€æ§‹æˆã€é »åº¦ã€ãƒãƒã‚¿ã‚¤ã‚ºã‚’è©³ç´°ã«åˆ†æ
"""

import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv
from collections import Counter
import re

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from social_media.x_twitter import get_twitter_client

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


def analyze_tweet_frequency(tweets_data):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆé »åº¦ã‚’åˆ†æ
    
    Args:
        tweets_data: ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        é »åº¦åˆ†æçµæœ
    """
    if not tweets_data:
        return None
    
    # æŠ•ç¨¿æ™‚é–“ã‚’åˆ†æ
    hourly_counts = Counter()
    daily_counts = Counter()
    
    for tweet in tweets_data:
        if tweet.get('created_at'):
            try:
                created_at = datetime.fromisoformat(tweet['created_at'].replace('Z', '+00:00'))
                hour = created_at.hour
                day_of_week = created_at.weekday()  # 0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥
                
                hourly_counts[hour] += 1
                daily_counts[day_of_week] += 1
            except:
                pass
    
    # 1æ—¥ã®å¹³å‡ãƒ„ã‚¤ãƒ¼ãƒˆæ•°
    if tweets_data:
        days_span = 7  # ä»®ã«7æ—¥é–“ã¨ã—ã¦è¨ˆç®—
        avg_daily_tweets = len(tweets_data) / days_span
    
    return {
        'avg_daily_tweets': avg_daily_tweets if tweets_data else 0,
        'hourly_distribution': dict(hourly_counts.most_common(24)),
        'daily_distribution': dict(daily_counts.most_common(7)),
        'peak_hours': [hour for hour, _ in hourly_counts.most_common(3)],
    }


def analyze_monetization(tweets_data):
    """
    ãƒãƒã‚¿ã‚¤ã‚ºæ–¹æ³•ã‚’åˆ†æ
    
    Args:
        tweets_data: ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        ãƒãƒã‚¿ã‚¤ã‚ºåˆ†æçµæœ
    """
    if not tweets_data:
        return None
    
    monetization_patterns = {
        'affiliate_links': 0,  # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯
        'product_reviews': 0,  # å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼
        'promotional_content': 0,  # ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        'affiliate_rate': 0.0,  # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã®å‰²åˆ
    }
    
    # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    affiliate_patterns = [
        r'amazon\.co\.jp',  # Amazon
        r'rakuten\.co\.jp',  # Rakuten
        r'a8\.net',  # A8.net
        r'af\.moshimo\.com',  # ã‚‚ã—ã‚‚ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆ
        r'u\.to',  # çŸ­ç¸®URLï¼ˆã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆã®å¯èƒ½æ€§ï¼‰
        r'bit\.ly',  # çŸ­ç¸®URL
    ]
    
    product_keywords = [
        r'ãŠã™ã™ã‚', r'ãƒ¬ãƒ“ãƒ¥ãƒ¼', r'è©¦ã—ã¦ã¿ãŸ', r'ä½¿ã£ã¦ã¿ãŸ',
        r'è³¼å…¥', r'è²·ã£ã¦', r'å•†å“', r'è£½å“', r'ã‚µãƒ¼ãƒ“ã‚¹',
    ]
    
    for tweet in tweets_data:
        text = tweet.get('text', '')
        
        # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
        has_affiliate = False
        for pattern in affiliate_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                has_affiliate = True
                monetization_patterns['affiliate_links'] += 1
                break
        
        # å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        if any(re.search(keyword, text) for keyword in product_keywords):
            monetization_patterns['product_reviews'] += 1
        
        # ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆãƒªãƒ³ã‚¯ + å•†å“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰
        if has_affiliate and any(re.search(keyword, text) for keyword in product_keywords):
            monetization_patterns['promotional_content'] += 1
    
    # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã®å‰²åˆ
    total_tweets = len(tweets_data)
    if total_tweets > 0:
        monetization_patterns['affiliate_rate'] = monetization_patterns['affiliate_links'] / total_tweets * 100
    
    return monetization_patterns


def analyze_tweet_structure(tweets_data):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆæ§‹æˆã‚’åˆ†æ
    
    Args:
        tweets_data: ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        æ§‹æˆåˆ†æçµæœ
    """
    if not tweets_data:
        return None
    
    structure_patterns = {
        'avg_line_breaks': 0,
        'has_title_rate': 0.0,
        'has_bullet_rate': 0.0,
        'has_emoji_rate': 0.0,
        'has_number_rate': 0.0,
        'has_url_rate': 0.0,
        'avg_length': 0,
        'common_title_markers': [],
    }
    
    title_markers = []
    line_breaks_list = []
    lengths = []
    
    title_patterns = [
        r'^ã€', r'^ã€Œ', r'^ã€', r'^â– ', r'^â–¶', r'^â—', r'^â—†', r'^â–¼',
    ]
    
    bullet_patterns = [r'[ãƒ»â€¢â†’]', r'^\d+[\.ã€]', r'^[-*]']
    
    for tweet in tweets_data:
        text = tweet.get('text', '')
        
        # æ”¹è¡Œæ•°
        line_breaks = text.count('\n')
        line_breaks_list.append(line_breaks)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ã‚«ãƒ¼ã®æœ‰ç„¡
        has_title = any(re.search(pattern, text) for pattern in title_patterns)
        if has_title:
            structure_patterns['has_title_rate'] += 1
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ã‚«ãƒ¼ã‚’æŠ½å‡º
            for pattern in title_patterns:
                match = re.search(pattern, text)
                if match:
                    marker = text[match.start():match.end()+10]  # ãƒãƒ¼ã‚«ãƒ¼ä»¥é™10æ–‡å­—
                    title_markers.append(marker[:20])
        
        # ç®‡æ¡æ›¸ãã®æœ‰ç„¡
        if any(re.search(pattern, text, re.MULTILINE) for pattern in bullet_patterns):
            structure_patterns['has_bullet_rate'] += 1
        
        # çµµæ–‡å­—ã®æœ‰ç„¡
        if re.search(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿]', text):
            structure_patterns['has_emoji_rate'] += 1
        
        # æ•°å­—ã®æœ‰ç„¡
        if re.search(r'\d+', text):
            structure_patterns['has_number_rate'] += 1
        
        # URLã®æœ‰ç„¡
        if re.search(r'https?://', text):
            structure_patterns['has_url_rate'] += 1
        
        # æ–‡å­—æ•°
        lengths.append(len(text))
    
    # å¹³å‡å€¤ã‚’è¨ˆç®—
    total = len(tweets_data)
    if total > 0:
        structure_patterns['avg_line_breaks'] = sum(line_breaks_list) / total
        structure_patterns['has_title_rate'] = structure_patterns['has_title_rate'] / total * 100
        structure_patterns['has_bullet_rate'] = structure_patterns['has_bullet_rate'] / total * 100
        structure_patterns['has_emoji_rate'] = structure_patterns['has_emoji_rate'] / total * 100
        structure_patterns['has_number_rate'] = structure_patterns['has_number_rate'] / total * 100
        structure_patterns['has_url_rate'] = structure_patterns['has_url_rate'] / total * 100
        structure_patterns['avg_length'] = sum(lengths) / total
    
    # ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ã‚«ãƒ¼
    marker_counter = Counter(title_markers)
    structure_patterns['common_title_markers'] = [marker for marker, _ in marker_counter.most_common(5)]
    
    return structure_patterns


def analyze_advanced_buzz_account(username, days=7):
    """
    é«˜åº¦ãªãƒã‚ºã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æï¼ˆå†…å®¹ã€æ§‹æˆã€é »åº¦ã€ãƒãƒã‚¿ã‚¤ã‚ºï¼‰
    
    Args:
        username: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåï¼ˆ@ãªã—ï¼‰
        days: åˆ†ææœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    
    Returns:
        åˆ†æçµæœ
    """
    try:
        client = get_twitter_client()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
        user = client.get_user(username=username)
        if not user.data:
            print(f"âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: @{username}")
            return None
        
        user_id = user.data.id
        follower_count = user.data.public_metrics.get('followers_count', 0) if user.data.public_metrics else 0
        
        print(f"ğŸ“Š é«˜åº¦ãªåˆ†æ: @{username}")
        print(f"   ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {follower_count:,}")
        
        # æœ€è¿‘ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆæœ€å¤§100ä»¶ï¼‰
        tweets = client.get_users_tweets(
            id=user_id,
            max_results=100,
            tweet_fields=['created_at', 'public_metrics', 'text']
        )
        
        if not tweets.data:
            print(f"âš ï¸ ãƒ„ã‚¤ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        # ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
        tweets_data = []
        high_engagement_tweets = []
        
        for tweet in tweets.data:
            metrics = tweet.public_metrics if hasattr(tweet, 'public_metrics') else {}
            likes = metrics.get('like_count', 0)
            retweets = metrics.get('retweet_count', 0)
            replies = metrics.get('reply_count', 0)
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—
            engagement_rate = (likes + retweets * 2 + replies * 2) / max(follower_count, 1) * 100
            
            tweet_data = {
                'text': tweet.text,
                'likes': likes,
                'retweets': retweets,
                'replies': replies,
                'engagement_rate': engagement_rate,
                'created_at': tweet.created_at.isoformat() if tweet.created_at else None
            }
            
            tweets_data.append(tweet_data)
            
            # é«˜ã„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ½å‡º
            if engagement_rate > 1.0:  # 1%ä»¥ä¸Š
                high_engagement_tweets.append(tweet_data)
        
        # å„ç¨®åˆ†æã‚’å®Ÿè¡Œ
        frequency_analysis = analyze_tweet_frequency(tweets_data)
        monetization_analysis = analyze_monetization(tweets_data)
        structure_analysis = analyze_tweet_structure(tweets_data)
        
        # é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆã®åˆ†æ
        high_engagement_structure = analyze_tweet_structure(high_engagement_tweets) if high_engagement_tweets else None
        
        analysis_result = {
            'username': username,
            'follower_count': follower_count,
            'total_tweets_analyzed': len(tweets_data),
            'high_engagement_count': len(high_engagement_tweets),
            'frequency': frequency_analysis,
            'monetization': monetization_analysis,
            'structure': structure_analysis,
            'high_engagement_structure': high_engagement_structure,
            'recommendations': []
        }
        
        # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
        recommendations = []
        
        if frequency_analysis and frequency_analysis.get('avg_daily_tweets', 0) > 0:
            recommendations.append(f"å¹³å‡æŠ•ç¨¿é »åº¦: 1æ—¥{frequency_analysis['avg_daily_tweets']:.1f}å›")
            if frequency_analysis.get('peak_hours'):
                peak_hours_str = 'ã€'.join([f"{h}æ™‚" for h in frequency_analysis['peak_hours']])
                recommendations.append(f"åŠ¹æœçš„ãªæŠ•ç¨¿æ™‚é–“: {peak_hours_str}")
        
        if monetization_analysis:
            if monetization_analysis.get('affiliate_rate', 0) > 0:
                recommendations.append(f"ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ä½¿ç”¨ç‡: {monetization_analysis['affiliate_rate']:.1f}%")
            if monetization_analysis.get('product_reviews', 0) > 0:
                recommendations.append(f"å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼é »åº¦: {monetization_analysis['product_reviews']}/{len(tweets_data)}ãƒ„ã‚¤ãƒ¼ãƒˆ")
        
        if structure_analysis:
            if structure_analysis.get('has_title_rate', 0) > 50:
                recommendations.append(f"ã‚¿ã‚¤ãƒˆãƒ«ä½¿ç”¨ç‡: {structure_analysis['has_title_rate']:.1f}%")
            if structure_analysis.get('avg_line_breaks', 0) > 2:
                recommendations.append(f"å¹³å‡æ”¹è¡Œæ•°: {structure_analysis['avg_line_breaks']:.1f}è¡Œ")
        
        analysis_result['recommendations'] = recommendations
        
        return analysis_result
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None


def compare_advanced_accounts(accounts_data):
    """
    è¤‡æ•°ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’é«˜åº¦ã«æ¯”è¼ƒ
    
    Args:
        accounts_data: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ†æçµæœã®ãƒªã‚¹ãƒˆ
    
    Returns:
        å…±é€šç‚¹åˆ†æçµæœ
    """
    if not accounts_data:
        return None
    
    common_patterns = {
        'avg_frequency': 0,
        'avg_affiliate_rate': 0,
        'common_structure_patterns': {},
        'recommendations': []
    }
    
    frequencies = []
    affiliate_rates = []
    
    for account_data in accounts_data:
        if account_data:
            if account_data.get('frequency') and account_data['frequency'].get('avg_daily_tweets'):
                frequencies.append(account_data['frequency']['avg_daily_tweets'])
            
            if account_data.get('monetization') and account_data['monetization'].get('affiliate_rate'):
                affiliate_rates.append(account_data['monetization']['affiliate_rate'])
    
    if frequencies:
        common_patterns['avg_frequency'] = sum(frequencies) / len(frequencies)
    
    if affiliate_rates:
        common_patterns['avg_affiliate_rate'] = sum(affiliate_rates) / len(affiliate_rates)
    
    # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    recommendations = []
    
    if common_patterns['avg_frequency'] > 0:
        recommendations.append(f"æ¨å¥¨æŠ•ç¨¿é »åº¦: 1æ—¥{common_patterns['avg_frequency']:.1f}å›")
    
    if common_patterns['avg_affiliate_rate'] > 0:
        recommendations.append(f"æ¨å¥¨ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆä½¿ç”¨ç‡: {common_patterns['avg_affiliate_rate']:.1f}%")
    
    common_patterns['recommendations'] = recommendations
    
    return common_patterns


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python advanced_buzz_analyzer.py analyze <username> [days]")
        print("\nä¾‹:")
        print("  python advanced_buzz_analyzer.py analyze example_user 7")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == 'analyze':
        if len(sys.argv) < 3:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå¿…è¦ã§ã™")
            sys.exit(1)
        
        username = sys.argv[2].replace('@', '')
        days = int(sys.argv[3]) if len(sys.argv) > 3 else 7
        
        result = analyze_advanced_buzz_account(username, days)
        
        if result:
            print("\n" + "=" * 60)
            print("ğŸ“Š é«˜åº¦ãªåˆ†æçµæœ")
            print("=" * 60)
            
            print(f"\nğŸ“ˆ é »åº¦åˆ†æ:")
            if result.get('frequency'):
                freq = result['frequency']
                print(f"  å¹³å‡æŠ•ç¨¿é »åº¦: 1æ—¥{freq.get('avg_daily_tweets', 0):.1f}å›")
                if freq.get('peak_hours'):
                    print(f"  åŠ¹æœçš„ãªæŠ•ç¨¿æ™‚é–“: {', '.join([f'{h}æ™‚' for h in freq['peak_hours']])}")
            
            print(f"\nğŸ’° ãƒãƒã‚¿ã‚¤ã‚ºåˆ†æ:")
            if result.get('monetization'):
                mon = result['monetization']
                print(f"  ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ä½¿ç”¨ç‡: {mon.get('affiliate_rate', 0):.1f}%")
                print(f"  å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {mon.get('product_reviews', 0)}ä»¶")
            
            print(f"\nğŸ“ æ§‹æˆåˆ†æ:")
            if result.get('structure'):
                struct = result['structure']
                print(f"  å¹³å‡æ”¹è¡Œæ•°: {struct.get('avg_line_breaks', 0):.1f}è¡Œ")
                print(f"  ã‚¿ã‚¤ãƒˆãƒ«ä½¿ç”¨ç‡: {struct.get('has_title_rate', 0):.1f}%")
                print(f"  çµµæ–‡å­—ä½¿ç”¨ç‡: {struct.get('has_emoji_rate', 0):.1f}%")
                print(f"  å¹³å‡æ–‡å­—æ•°: {struct.get('avg_length', 0):.0f}æ–‡å­—")
            
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for rec in result.get('recommendations', []):
                print(f"  - {rec}")
    
    else:
        print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
        sys.exit(1)


if __name__ == '__main__':
    main()
