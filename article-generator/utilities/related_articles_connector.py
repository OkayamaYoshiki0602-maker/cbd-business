#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é–¢é€£è¨˜äº‹ã®è‡ªå‹•é€£æºãƒ»æ¨å¥¨æ©Ÿèƒ½
æ—¢å­˜è¨˜äº‹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€æ–°è¦è¨˜äº‹ã«æœ€é©ãªé–¢é€£è¨˜äº‹ã‚’è‡ªå‹•æ¨å¥¨
"""

import os
import sys
import re
from pathlib import Path
from typing import List, Dict, Tuple
from dotenv import load_dotenv

sys.path.insert(0, str(Path(__file__).parent.parent))

from google_services.google_sheets import read_spreadsheet
import google.generativeai as genai

load_dotenv()

ARTICLE_SPREADSHEET_ID = os.getenv('ARTICLE_SPREADSHEET_ID', '1-2L6C3NpF8vqnXxHWKP-Js3TMFKYE73tTtxdkZVPTaM')
ARTICLE_LIST_SHEET = 'Article_List'
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

genai.configure(api_key=GEMINI_API_KEY)


def extract_keywords_from_title(title: str) -> List[str]:
    """
    è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    """
    # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    # ä¾‹ï¼šã€ŒCBDåˆå¿ƒè€…ã‚¬ã‚¤ãƒ‰ã€â†’ ["CBD", "åˆå¿ƒè€…", "ã‚¬ã‚¤ãƒ‰"]
    
    # æ‹¬å¼§å†…ã‚’å‰Šé™¤
    title_clean = re.sub(r'ã€.*?ã€‘', '', title)
    title_clean = re.sub(r'[ã€ã€‘\[\]()]', '', title_clean)
    
    # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆåœæ­¢èªã§ãªã„ï¼‰ã‚’æŠ½å‡º
    keywords = []
    
    # åˆ†å‰²
    words = re.split(r'[ãƒ»ï¼šã€\s]', title_clean)
    
    for word in words:
        if len(word) > 2 and word not in ['ã“ã¨', 'ã§ã™', 'ã™ã‚‹', 'ã“ã®', 'ãã‚Œ', 'ã‚ã‚‹']:
            keywords.append(word)
    
    return keywords[:5]  # æœ€å¤§5å€‹


def find_related_articles(
    new_article_title: str,
    new_article_keywords: str,
    all_articles: List[Dict],
    max_related: int = 3
) -> List[Tuple[str, str, float]]:
    """
    æ–°è¦è¨˜äº‹ã«å¯¾ã™ã‚‹é–¢é€£è¨˜äº‹ã‚’æ¤œç´¢
    
    Args:
        new_article_title: æ–°è¦è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
        new_article_keywords: æ–°è¦è¨˜äº‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
        all_articles: å…¨æ—¢å­˜è¨˜äº‹ã®ãƒªã‚¹ãƒˆ
        max_related: æ¨å¥¨ã™ã‚‹é–¢é€£è¨˜äº‹ã®æœ€å¤§æ•°
    
    Returns:
        [(è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«, è¨˜äº‹URL, é–¢é€£åº¦ã‚¹ã‚³ã‚¢), ...] ã®ãƒªã‚¹ãƒˆ
    """
    
    # æ–°è¦è¨˜äº‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†è§£
    new_keywords = set([k.strip() for k in new_article_keywords.split(",")])
    new_keywords.update(extract_keywords_from_title(new_article_title))
    
    print(f"   ğŸ“ æ–°è¦è¨˜äº‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(list(new_keywords)[:5])}")
    
    # æ—¢å­˜è¨˜äº‹ã¨ã®ãƒãƒƒãƒãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    scores = []
    
    for article in all_articles:
        if len(article) < 5:
            continue
        
        article_title = article[2] if len(article) > 2 else ""
        article_url = article[4] if len(article) > 4 else ""
        
        # åŒã˜è¨˜äº‹ã¯é™¤å¤–
        if article_title == new_article_title:
            continue
        
        # æ—¢å­˜è¨˜äº‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        article_keywords = set(extract_keywords_from_title(article_title))
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒãƒãƒ³ã‚°åº¦ï¼ˆJaccardä¿‚æ•°ï¼‰ã‚’è¨ˆç®—
        if not article_keywords:
            continue
        
        intersection = len(new_keywords & article_keywords)
        union = len(new_keywords | article_keywords)
        
        if union > 0:
            similarity = intersection / union
            scores.append((article_title, article_url, similarity))
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
    scores.sort(key=lambda x: x[2], reverse=True)
    
    # é–¢é€£åº¦ãŒ0.3ä»¥ä¸Šã®ã‚‚ã®ã‚’è¿”ã™
    related = [(t, u, s) for t, u, s in scores if s >= 0.3][:max_related]
    
    return related


def generate_related_articles_section(
    related_articles: List[Tuple[str, str, float]]
) -> str:
    """
    é–¢é€£è¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®HTML ã‚’ç”Ÿæˆ
    """
    
    if not related_articles:
        return ""
    
    html = """
<hr class="wp-block-separator has-css-opacity is-style-wide"/>

<h3 class="wp-block-heading">é–¢é€£è¨˜äº‹</h3>

<p>ã“ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€ã•ã‚‰ã«è©³ã—ãçŸ¥ã‚ŠãŸã„æ–¹ã¯ä»¥ä¸‹ã®è¨˜äº‹ã‚‚å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
"""
    
    for title, url, score in related_articles:
        # URLãŒãªã„å ´åˆã¯æ¨å¥¨ã‹ã‚‰é™¤å¤–
        if not url or url.startswith('http'):
            # å¤–éƒ¨ãƒªãƒ³ã‚¯ã®å ´åˆã¯ãã®ã¾ã¾
            html += f'  <li><a href="{url}" target="_blank" rel="noopener noreferrer">{title}</a></li>\n'
        else:
            # å†…éƒ¨ãƒªãƒ³ã‚¯
            html += f'  <li><a href="/post/{url}">{title}</a> - é–¢é€£ãƒ†ãƒ¼ãƒã®è©³ç´°</li>\n'
    
    html += """</ul>
"""
    
    return html


def inject_related_articles_to_html(
    article_html: str,
    related_articles: List[Tuple[str, str, float]]
) -> str:
    """
    æ—¢å­˜ã®è¨˜äº‹HTMLã«é–¢é€£è¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ³¨å…¥
    """
    
    related_section = generate_related_articles_section(related_articles)
    
    if not related_section:
        return article_html
    
    # ã€Œå‚è€ƒæ–‡çŒ®ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å¾Œã«é–¢é€£è¨˜äº‹ã‚’æŒ¿å…¥
    # ã¾ãŸã¯ã€æœ€å¾Œã®</div>ã®å‰ã«æŒ¿å…¥
    
    # å‚è€ƒæ–‡çŒ®ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
    param_section_match = re.search(r'(<h3 class="wp-block-heading">å‚è€ƒæ–‡çŒ®.*?</ul>)', article_html, re.DOTALL)
    
    if param_section_match:
        insert_pos = param_section_match.end()
        article_html = article_html[:insert_pos] + related_section + article_html[insert_pos:]
    else:
        # æœ€å¾Œã®</ul>ã®å¾Œã«æŒ¿å…¥
        last_ul_pos = article_html.rfind('</ul>')
        if last_ul_pos != -1:
            article_html = article_html[:last_ul_pos + 5] + related_section + article_html[last_ul_pos + 5:]
        else:
            # æœ€å¾Œã«è¿½åŠ 
            article_html = article_html.rstrip() + "\n" + related_section
    
    return article_html


def get_all_articles_from_list() -> List[Dict]:
    """
    Article_List ã‚·ãƒ¼ãƒˆã‹ã‚‰å…¨è¨˜äº‹ã‚’å–å¾—
    """
    
    try:
        data = read_spreadsheet(ARTICLE_SPREADSHEET_ID, f"{ARTICLE_LIST_SHEET}!A:E")
        
        if not data or len(data) < 2:
            return []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
        articles = []
        for row in data[1:]:
            if row and len(row) > 2 and row[2]:  # ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚‹
                articles.append(row)
        
        return articles
    
    except Exception as e:
        print(f"âš ï¸ è¨˜äº‹ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def find_related_articles_by_ai(
    new_article_title: str,
    new_article_keywords: str,
    all_articles: List[Dict]
) -> List[Tuple[str, str, str]]:
    """
    AI ã‚’ä½¿ç”¨ã—ã¦é–¢é€£è¨˜äº‹ã‚’ã‚ˆã‚Šé«˜åº¦ã«æ¨å¥¨
    ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã§è‡ªå‹•çš„ã«é–¢é€£è¨˜äº‹ã‚’åˆ¤æ–­ï¼‰
    
    Returns:
        [(è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«, è¨˜äº‹URL, æ¨å¥¨ç†ç”±), ...] ã®ãƒªã‚¹ãƒˆ
    """
    
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    # æ—¢å­˜è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ä¸€è¦§
    existing_titles = [article[2] for article in all_articles if len(article) > 2][:20]
    
    if not existing_titles:
        return []
    
    prompt = f"""ã‚ãªãŸã¯ CBD ã‚µã‚¤ãƒˆç·¨é›†è€…ã§ã™ã€‚æ–°è¦è¨˜äº‹ã¨æ—¢å­˜è¨˜äº‹ã‹ã‚‰ã€æœ€é©ãªé–¢é€£è¨˜äº‹ã‚’æ¨å¥¨ã—ã¦ãã ã•ã„ã€‚

ã€æ–°è¦è¨˜äº‹ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {new_article_title}
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {new_article_keywords}

ã€æ—¢å­˜è¨˜äº‹ï¼ˆå€™è£œï¼‰ã€‘
{chr(10).join([f'{i+1}. {t}' for i, t in enumerate(existing_titles)])}

ã€æŒ‡ç¤ºã€‘
æ–°è¦è¨˜äº‹ã«æœ€é©ãªé–¢é€£è¨˜äº‹ã‚’3ã¤ã¾ã§é¸ã‚“ã§ãã ã•ã„ã€‚
èª­è€…ãŒã€Œæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€ã¨ã—ã¦å‚è€ƒã«ãªã‚‹è¨˜äº‹ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã¯ä¸Šè¨˜ã®æ—¢å­˜è¨˜äº‹ã‹ã‚‰å®Œå…¨ä¸€è‡´ã™ã‚‹æ–¹ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
1. è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
2. è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
3. è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«

ï¼ˆæ¨å¥¨ã§ãã‚‹é–¢é€£è¨˜äº‹ãŒãªã„å ´åˆã¯ã€Œãªã—ã€ã¨è¨˜è¼‰ï¼‰

è¿”ç­”ã®ã¿ã€å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚
"""
    
    try:
        response = model.generate_content(prompt)
        suggestions = response.text.strip()
        
        if 'ãªã—' in suggestions or not suggestions:
            return []
        
        # æ¨å¥¨ç†ç”±ã‚’æŠ½å‡º
        recommendations = []
        for line in suggestions.split('\n'):
            if line.strip() and (line.startswith(('1.', '2.', '3.'))):
                # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
                title_match = re.match(r'^\d+\.\s*(.+?)$', line.strip())
                if title_match:
                    title = title_match.group(1).strip()
                    
                    # æ—¢å­˜è¨˜äº‹ã‹ã‚‰å®Œå…¨ä¸€è‡´ã‚’æ¤œç´¢
                    for article in all_articles:
                        if len(article) > 2 and article[2] and article[2].strip() == title:
                            url = article[4] if len(article) > 4 else ""
                            reason = f"é–¢é€£ãƒ†ãƒ¼ãƒã®è©³ç´°è§£èª¬"
                            recommendations.append((title, url, reason))
                            break
        
        return recommendations[:3]
    
    except Exception as e:
        print(f"âš ï¸ AI æ¨å¥¨ã‚¨ãƒ©ãƒ¼: {e}")
        return []


# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_related_articles_finder():
    """
    é–¢é€£è¨˜äº‹æ¨å¥¨ã®å‹•ä½œãƒ†ã‚¹ãƒˆ
    """
    
    print("ğŸ“ é–¢é€£è¨˜äº‹ã®è‡ªå‹•é€£æºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ\n")
    print("=" * 100)
    
    # æ—¢å­˜è¨˜äº‹ã‚’å–å¾—
    all_articles = get_all_articles_from_list()
    print(f"\nâœ… æ—¢å­˜è¨˜äº‹ã‚’å–å¾—ã—ã¾ã—ãŸ: {len(all_articles)}ä»¶\n")
    
    if len(all_articles) < 2:
        print("âš ï¸ æ—¢å­˜è¨˜äº‹ãŒè¶³ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®æ–°è¦è¨˜äº‹
    test_new_title = "CBDåˆå¿ƒè€…å‘ã‘ã®å®‰å…¨ãªé¸ã³æ–¹ã¨å§‹ã‚æ–¹"
    test_new_keywords = "CBD,åˆå¿ƒè€…,å®‰å…¨,é¸ã³æ–¹"
    
    print(f"ã€ãƒ†ã‚¹ãƒˆç”¨æ–°è¦è¨˜äº‹ã€‘")
    print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {test_new_title}")
    print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {test_new_keywords}\n")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®é–¢é€£è¨˜äº‹æ¤œç´¢
    print("ğŸ“‹ ã€æ–¹æ³•1ã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§é–¢é€£è¨˜äº‹ã‚’æ¤œç´¢\n")
    related_kw = find_related_articles(test_new_title, test_new_keywords, all_articles, max_related=3)
    
    print(f"  æ¤œç´¢çµæœ: {len(related_kw)}ä»¶\n")
    for i, (title, url, score) in enumerate(related_kw, 1):
        print(f"  {i}. {title}")
        print(f"     é–¢é€£åº¦: {score:.1%}")
        print()
    
    # HTMLç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("ğŸ“‹ ã€æ–¹æ³•2ã€‘HTMLé–¢é€£è¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ\n")
    related_section = generate_related_articles_section(related_kw)
    print("  ç”Ÿæˆã•ã‚ŒãŸHTML:")
    print(related_section[:200] + "..." if len(related_section) > 200 else related_section)
    
    print("\n" + "=" * 100)
    print("\nâœ… é–¢é€£è¨˜äº‹æ¨å¥¨æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")


if __name__ == '__main__':
    test_related_articles_finder()
